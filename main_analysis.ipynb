{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "na_values = ['NO CLUE', 'N/A', '0']\n",
    "# the request is not a dataframe but\n",
    "# TextFileReader object for iteration\n",
    "requests = pd.read_csv('311_data.csv',\n",
    "                       chunksize=1000000,\n",
    "                       na_values=na_values,\n",
    "                       low_memory=False)\n",
    "\n",
    "def chunk_data(requests):\n",
    "    chunk_list = []  # append each chunk df here\n",
    "    # Each chunk is in df format\n",
    "    for chunk in requests:\n",
    "        chunk_list.append(chunk)\n",
    "        # concat the list into dataframe\n",
    "    df_concat = pd.concat(chunk_list)\n",
    "\n",
    "    return df_concat\n",
    "\n",
    "def fix_zip_codes(zips):\n",
    "    # Truncate everything to length 5\n",
    "    zips = zips.str.slice(0, 5)\n",
    "\n",
    "    # Set 00000 zip codes to nan\n",
    "    zero_zips = zips == '00000'\n",
    "    zips[zero_zips] = np.nan\n",
    "\n",
    "    return zips\n",
    "\n",
    "\n",
    "df_req = chunk_data(requests)\n",
    "df_req['Incident Zip'] = fix_zip_codes(df_req['Incident Zip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dfObj.head())\n",
    "#print(dfObj.columns) # print column names\n",
    "df_req.rename(columns={\"Agency Name\": \"AgencyName\", \"Incident Zip\": \"IncidentZip\", \"Complaint Type\": \"ComplaintType\"})\n",
    "\n",
    "# Rename column names\n",
    "df_req.columns = df_req.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "#print(dfObj.columns) # print column names\n",
    "\n",
    "dfObj_agency = df_req.agency.unique() #Find unique elements in the column\n",
    "dfObj_agency_name = df_req.agency_name.unique() #Find unique elements in the column\n",
    "dfObj_incident_zip = df_req.incident_zip.unique() #Find unique elements in the column\n",
    "dfObj_complaint_type = df_req.complaint_type.unique() #Find unique elements in the column\n",
    "\n",
    "# print unique values in these columns:\n",
    "print('agency ' + str(len(dfObj_agency)))\n",
    "print('agency_name ' + str(len(dfObj_agency_name)))\n",
    "print('incident_zip ' + str(len(dfObj_incident_zip)))\n",
    "print('complaint_type ' + str(len(dfObj_complaint_type)))\n",
    "\n",
    "\n",
    "#print(dfObj_incident_zip) #Review unique names for missing data or odd format\n",
    "print(dfObj_agency) #Review unique names for missing data or odd format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_req.incident_zip.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "df_req.complaint_type.replace(regex=True,inplace=True,to_replace=r'[^a-zA-Z ]+',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_req.complaint_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "df_req.incident_zip.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total complaints count\n",
    "df_count = df_req.groupby(['complaint_type','incident_zip', 'agency']).size().reset_index(name=\"Total Count\")\n",
    "pd.set_option('display.max_rows', 50000)  # or 1000\n",
    "df_count.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "filename = '311_data.csv'\n",
    "df = dd.read_csv(filename, dtype='str')\n",
    "df = df.rename(columns={c: c.replace(' ', '') for c in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.IncidentZip.replace(regex=True,to_replace=r'\\D',value=r'')\n",
    "df.ComplaintType.replace(regex=True,to_replace=r'[^a-zA-Z ]+',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_count = df.groupby(['ComplaintType','IncidentZip', 'Agency']).size().reset_index()\n",
    "pd.set_option('display.max_rows', 50000)  # or 1000\n",
    "df_count.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_zip = df.groupby(['ComplaintType','IncidentZip']).size().reset_index()\n",
    "df_count_zip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_zip = df_count_zip.groupby('IncidentZip', group_keys = False).sum().reset_index()\n",
    "by_zip.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfObj = pd.read_csv(\"Book1.csv\")\n",
    "\n",
    "# Rename column names\n",
    "dfObj.columns = dfObj.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "\n",
    "dfObj_incident_zip_unique = dfObj.incident_zip.unique() #Find unique elements in the column\n",
    "dfObj_complaint_type_unique = dfObj.complaint_type.unique() #Find unique elements in the column\n",
    "\n",
    "\n",
    "Finaldf = pd.DataFrame(dfObj_complaint_type_unique, columns=['Complaint_Type'])\n",
    "\n",
    "for complaint_type_item in dfObj_complaint_type_unique:\n",
    "    df_temp1 = dfObj.loc[(dfObj['complaint_type'] == complaint_type_item)] #Extract dataframe with a particular complaint type\n",
    "    for zip_code_item in dfObj_incident_zip_unique:\n",
    "        df_temp2 = dfObj.loc[(dfObj['incident_zip'] == zip_code_item)] #Extract dataframe with a particular zip code\n",
    "        occurences= len(df_temp2.index) #Count number of rows for the data frame which has a particular ip code for a particular complaint type\n",
    "        Finaldf[str(zip_code_item)] = ''\n",
    "        Finaldf[str(zip_code_item)] = np.where(Finaldf['Complaint_Type'] == str(complaint_type_item), occurences, '')\n",
    "        #Fill in the cell in the 'zip code' column for a given row of a 'complaint type'\n",
    "\n",
    "export_csv = Finaldf.to_csv(r'Output.csv', index=None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env-gpu)",
   "language": "python",
   "name": "va-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
